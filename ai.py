# ai.py
import copy, math
from hello import DIRECTIONS    # â† é€™è£¡æ”¹æˆ hello è€Œä¸æ˜¯ reversi
import time

import numpy as np
from tensorflow.keras.models import load_model

model = load_model("reversi_policy_model.h5")

def predict_by_model(board, valid_moves):
    input_board = np.array(board).reshape(1, 8, 8, 1).astype(np.float32) / 2.0
    prediction = model.predict(input_board, verbose=0)[0].reshape(8, 8)

    # åªè€ƒæ…®åˆæ³•çš„è½å­é»ï¼Œé¸æ©Ÿç‡æœ€å¤§çš„é‚£ä¸€æ ¼
    best_move = None
    best_score = -float("inf")
    for r, c in valid_moves:
        if prediction[r][c] > best_score:
            best_score = prediction[r][c]
            best_move = (r, c)
    return best_move

POSITION_WEIGHTS = [
    [100, -20, 10, 5, 5, 10, -20, 100],
    [-20, -50, -2, -2, -2, -2, -50, -20],
    [10, -2, -1, -1, -1, -1, -2, 10],
    [5, -2, -1, -1, -1, -1, -2, 5],
    [5, -2, -1, -1, -1, -1, -2, 5],
    [10, -2, -1, -1, -1, -1, -2, 10],
    [-20, -50, -2, -2, -2, -2, -50, -20],
    [100, -20, 10, 5, 5, 10, -20, 100],
]

X_SQUARES = [
    (0,1), (1,0), (1,1),
    (0,6), (1,7), (1,6),
    (6,0), (7,1), (6,1),
    (7,6), (6,7), (6,6)
]



def is_stable(board, r, c):
    player = board[r][c]
    if player == 0:
        return False

    # è§’è½ â†’ æ°¸é ç©©å®š
    if (r, c) in [(0, 0), (0, 7), (7, 0), (7, 7)]:
        return True

    # è‹¥è©²ä½ç½®åœ¨é‚Šç•Œï¼Œä¸”ä¸€æ•´åˆ—/è¡Œéƒ½æ˜¯æˆ‘æ–¹å­ â†’ ç©©å®š
    if r in [0, 7] and all(board[r][i] == player for i in range(8)):
        return True
    if c in [0, 7] and all(board[i][c] == player for i in range(8)):
        return True

    # å¯æ“´å……æ›´å¤šåˆ¤å®šï¼ˆå¦‚é‚Šè§’å±•å»¶ç©©å®šå€ï¼‰ï¼Œä½†é€™æ¨£å·²è¶³ä»¥å¢å¼· AI æ°´æº–
    return False



def evaluate(board, player):
    opp = 2 if player == 1 else 1
    my_score = opp_score = 0
    my_moves = len(get_valid_moves(board, player))
    opp_moves = len(get_valid_moves(board, opp))
    my_stable = opp_stable = 0
    my_discs = opp_discs = 0
    x_penalty = 0
    flip_advantage = 0

    total_discs = 0
    for r in range(8):
        for c in range(8):
            piece = board[r][c]
            if piece != 0:
                total_discs += 1

            if piece == player:
                my_discs += 1
                my_score += POSITION_WEIGHTS[r][c]
                if is_stable(board, r, c):
                    my_stable += 1
                if (r, c) in X_SQUARES:
                    x_penalty -= 15
            elif piece == opp:
                opp_discs += 1
                opp_score += POSITION_WEIGHTS[r][c]
                if is_stable(board, r, c):
                    opp_stable += 1
                if (r, c) in X_SQUARES:
                    x_penalty += 15

    # 1ï¸âƒ£ ç©©å®šå­
    stability_score = 15 * (my_stable - opp_stable)

    # 2ï¸âƒ£ è¡Œå‹•åŠ›
    mobility_score = 0
    if my_moves + opp_moves > 0:
        mobility_score = 100 * (my_moves - opp_moves) / (my_moves + opp_moves)

    # 3ï¸âƒ£ åƒå­æ•¸é‡ï¼ˆä¸­æœŸé‡è¦ï¼‰
    # â†’ å‡è¨­é›»è…¦æ¯å›åˆéƒ½åƒæ¯”å°æ‰‹å¤šçš„ï¼Œé€™æ˜¯å¥½äº‹
    flip_score = (my_discs - opp_discs) * 2 if total_discs < 54 else 0  # é¿å…çµ‚å±€åæ•ˆæœ

    # 4ï¸âƒ£ çµ‚å±€ä»¥å­æ•¸å‹è² 
    endgame_score = 0
    if total_discs >= 58:
        endgame_score = 500 * (my_discs - opp_discs) / (my_discs + opp_discs)

    return (my_score - opp_score) + stability_score + mobility_score + x_penalty + flip_score + endgame_score

def get_valid_moves(board, player):
    opp = 2 if player==1 else 1
    moves = []
    for r in range(8):
        for c in range(8):
            if board[r][c]!=0: continue
            for dx,dy in DIRECTIONS:
                x,y = r+dx, c+dy; cnt=0
                while 0<=x<8 and 0<=y<8 and board[x][y]==opp:
                    x+=dx; y+=dy; cnt+=1
                if cnt>0 and 0<=x<8 and 0<=y<8 and board[x][y]==player:
                    moves.append((r,c))
                    break
    return moves

def apply_move(board, move, player):
    newb = copy.deepcopy(board)
    r,c = move; newb[r][c]=player
    opp = 2 if player==1 else 1
    for dx,dy in DIRECTIONS:
        x,y = r+dx, c+dy; flip=[]
        while 0<=x<8 and 0<=y<8 and newb[x][y]==opp:
            flip.append((x,y)); x+=dx; y+=dy
        if flip and 0<=x<8 and 0<=y<8 and newb[x][y]==player:
            for fx,fy in flip: newb[fx][fy]=player
    return newb

def minimax(board, player, depth, alpha, beta, maximizing, start_time, time_limit):
    """
    Alpha-Beta æ­é… Move Ordering + Early Cutoffï¼ˆæ™‚é–“é™åˆ¶ & çµ‚å±€å„ªåŒ–ï¼‰
    """
    # â° æª¢æŸ¥æ™‚é–“æ˜¯å¦è¶…éé™åˆ¶
    if time.time() - start_time > time_limit:
        return evaluate(board, player), None

    # ğŸ è‹¥æ£‹å±€æ¥è¿‘çµæŸï¼Œç›´æ¥è©•ä¼°ç›¤é¢ï¼ˆä¸è¦å†å±•é–‹ï¼‰
    if sum(row.count(0) for row in board) <= 6:
        return evaluate(board, player), None

    current_player = player if maximizing else (2 if player == 1 else 1)
    moves = get_valid_moves(board, current_player)

    if depth == 0 or not moves:
        return evaluate(board, player), None

    # ğŸ¯ Move Orderingï¼šå„ªå…ˆè§’è½ã€é‚Šç·£ï¼ˆå‰ªææ›´å¿«ï¼‰
    moves.sort(key=lambda m: POSITION_WEIGHTS[m[0]][m[1]], reverse=maximizing)

    best_move = None

    if maximizing:
        value = -math.inf
        for move in moves:
            new_board = apply_move(board, move, player)
            v, _ = minimax(new_board, player, depth - 1, alpha, beta, False, start_time, time_limit)
            if v > value:
                value = v
                best_move = move
            alpha = max(alpha, value)
            if alpha >= beta:
                break
        return value, best_move
    else:
        value = math.inf
        opp = 2 if player == 1 else 1
        for move in moves:
            new_board = apply_move(board, move, opp)
            v, _ = minimax(new_board, player, depth - 1, alpha, beta, True, start_time, time_limit)
            if v < value:
                value = v
                best_move = move
            beta = min(beta, value)
            if alpha >= beta:
                break
        return value, best_move
    
# def get_best_move(board, player, max_depth=2, time_limit=0.01):

#     """
#     ä½¿ç”¨ Iterative Deepening + Move Orderingï¼Œæ‰¾å‡ºæœ€ä½³ä¸‹ä¸€æ­¥ã€‚
#     è‹¥è¶…é time_limitï¼ˆç§’ï¼‰ï¼Œæœƒææ—©å›å‚³ä¸Šä¸€è¼ªçµæœã€‚
#     """
#     start_time = time.time()
#     best_move = None
#     current_depth = 1

#     while current_depth <= max_depth:
#         value, move = minimax(board, player, current_depth, -math.inf, math.inf, True, start_time, time_limit)
#         if time.time() - start_time > time_limit:
#             break
#         best_move = move
#         current_depth += 1

#     return best_move

def get_best_move(board, player, max_depth=2, time_limit=0.05, use_model=False):
    valid_moves = get_valid_moves(board, player)
    if not valid_moves:
        return None

    if use_model:
        return predict_by_model(board, valid_moves)
    else:
        # åŸæœ¬çš„ Alpha-Beta ç­–ç•¥
        start_time = time.time()
        best_move = None
        current_depth = 1
        while current_depth <= max_depth:
            value, move = minimax(board, player, current_depth, -math.inf, math.inf, True, start_time, time_limit)
            if time.time() - start_time > time_limit:
                break
            best_move = move
            current_depth += 1
        return best_move

def choose_best_return_piece(board, pending_return, player):
    """
    å¾ pending_return è£¡é¸å‡ºä¸€å€‹ã€Œé‚„å›å»å°å°æ‰‹æœ€æ²’åˆ©ã€çš„é»ã€‚
    """
    import copy

    best_score = -math.inf
    best_piece = None
    opp = 2 if player == 1 else 1

    for rx, ry in pending_return:
        # æ¨¡æ“¬ä¸€å€‹ boardï¼šé‚„é€™é¡†çµ¦å°æ‰‹ï¼Œå…¶å®ƒé‚„æ˜¯è‡ªå·±é¡è‰²
        test_board = copy.deepcopy(board)
        for fx, fy in pending_return:
            test_board[fx][fy] = player
        test_board[rx][ry] = opp  # é‚„é€™ä¸€é¡†

        score = evaluate(test_board, player)
        if score > best_score:
            best_score = score
            best_piece = (rx, ry)

    return best_piece

